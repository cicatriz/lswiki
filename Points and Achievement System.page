Technical intro: I seemed to finally debugged the points middleware so that at least a couple things are working as intended. The way this works is that the middleware runs anytime any view is called, then if the view is matched to any one that should add points for a user, it looks at the request and the function parameters to determine who to give points to and adds that total to the database (a field under Enrollment). 

Good reasons to keep this as a database value rather than computing it each time: a) will never decrease b) much easier to look at quickly -- like comparing all of the users against each other. I'm still not sure whether we should also have a model that keeps track of all of the point additions. Some of them are reconstructable, but again that introduces the problem of vanishing points (vanishing the ability to account for points). 

Design intro: Gaining points is fun and addictive. In the case of Real Analysis, it allows us to determine who is participating. It also lets us incentivize users in certain ways to make the "society" of each course work better. One design philosophy for points is that they should be small and easy to acquire -- this avoids the problem of reducing internal motivation by giving out huge rewards. Another thing to consider is that random interval training seems to be extremely effective, so we might want to do x points with probability p (see http://www.cracked.com/article_18461_5-creepy-ways-video-games-are-trying-to-get-you-addicted.html). So there is a question of whether users should know how they're getting points at all. On one hand it's fun to try to guess what will give you lots of points; on the other 

Action ----- Reward ----- (Not-so-)Hidden agenda

Student points

* Vote for someone's card ----- +1 point/vote ----- Students should give feedback to each other
* Get your own card voted up ----- +5 points/vote ----- Students should produce good questions and answers
* Study your own cards ----- +2 points/5 views ----- Students should study (and stick with cards by studying them multiple times)
* Study the course concept cards1 ----- +5 points/5% ----- Students should study what the teacher wants them to
* Complete all reviews for a day ----- +8 points/day ----- Students should study daily
* Instructor-awarded points ------ varies ------ Students should do awesome things that we can't even think of!

1This is tricky because concept cards may (should!) grow over time.

Teacher points

placeholder

One way we can evaluate these metrics is by trying to predict a typical usage pattern throughout a course and see how the points break down. We can also do extreme cases (someone trying to game the system by voting for every stupid card that they come across), and make sure they don't bypass a more normal but studious user.

Badges - This is something you can witness at StackOverflow (and probably Foursquare but I have no experience with it). Here are some random ideas. 

* “Ironman” - Complete all reviews each day for a week: 50
* “Master” - know all concepts for a certified course: 50
* “Polymath” - master 5 courses: 100
* “Von Neumann” - master 10 courses: 200
* “Da Vinci” - master 25 courses: 300
* “Socrates” - create question with 50+ users: 50
* “Keating” - create course with 50+ users: 50
* “Einstein” - accumulate total score of 1000 from question answers: 500

Some links about applied game design:
* http://gamingtheclassroom.wordpress.com/syllabus/
* see also: http://news.ycombinator.com/item?id=2089735
* to watch: http://www.youtube.com/watch?v=0tg55pdNMxw&feature=related
* http://www.fastcompany.com/magazine/151/everyones-a-player.html
* http://www.cracked.com/article_18461_5-creepy-ways-video-games-are-trying-to-get-you-addicted.html

See also/combine with/separate out gamification from: [Productivity]()
